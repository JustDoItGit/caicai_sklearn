{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 单层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 回归神经网络：线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[0, 0], [1, 0], [0, 1], [1, 1]])\n",
    "z_reg = np.array([-0.2, -0.05, -0.05, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2 , -0.05, -0.05,  0.1 ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义实现简单线性回归的函数\n",
    "def LinearR(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.2  # 给定一组系数w和b\n",
    "    z = x1*w1 + x2*w2 + b  # z是系数*特征后加和的结果\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2 , -0.05, -0.05,  0.1 ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinearR(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二分类单层神经网络：sigmoid与阶跃函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重新定义数据中的标签\n",
    "y_and = [0, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据sigmoid公式定义sigmoid函数\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AND_sigmoid(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.2  # 给定的系数w和b不变\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    o = sigmoid(z)  # 使用sigmoid函数将回归结果转换到(0,1)之间\n",
    "    y = (o >= 0.5).astype(int)\n",
    "#     y = [int(x) for x in o >= 0.5] #根据阈值0.5，将(0,1)之间的概率转变为分类0和1\n",
    "    return o, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o:sigmoid函数返回的概率结果\n",
    "# y:对概率结果按阈值进行划分后，形成的0和1，也就是分类标签\n",
    "o, y_sigm = AND_sigmoid(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.450166  , 0.4875026 , 0.4875026 , 0.52497919])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sigm == y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sigm == y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sigm == y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_sigm == y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 阶跃函数\n",
    "def AND(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.23  # 和sigmoid相似的w和b\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    y = (z >= 0).astype(int)\n",
    "#     y = [int(x) for x in z >= 0]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AND(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多分类单层神经网络：softmax回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-d09822f2937e>:2: RuntimeWarning: overflow encountered in exp\n",
      "  np.exp(z) / np.sum(np.exp(z))   # softmax函数的运算\n",
      "<ipython-input-19-d09822f2937e>:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  np.exp(z) / np.sum(np.exp(z))   # softmax函数的运算\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = np.array([1010, 1000, 990])\n",
    "np.exp(z) / np.sum(np.exp(z))   # softmax函数的运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义softmax函数\n",
    "def softmax(z):\n",
    "    c = np.max(z)\n",
    "    exp_z = np.exp(z - c)  # 溢出对策\n",
    "    sum_exp_z = np.sum(exp_z)\n",
    "    o = exp_z / sum_exp_z\n",
    "    return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99954600e-01, 4.53978686e-05, 2.06106005e-09])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(softmax(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多层神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 异或门问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 与门图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('seaborn-whitegrid')  # 设置图像的风格\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(5, 3))  # 设置画布大小\n",
    "plt.title(\"AND GATE\", fontsize=16)  # 设置图像标题\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_and, cmap=\"rainbow\")  # 绘制散点图\n",
    "x = np.arange(-1, 3, 0.5)\n",
    "plt.plot(x, (0.23-0.15*x)/0.15,  # 这里是从直线的表达式变型出的x2 = 的式子\n",
    "         color=\"k\", linestyle=\"--\")\n",
    "plt.xlim(-1, 3)  # 设置横纵坐标尺寸 plt.ylim(-1,3)\n",
    "plt.grid(alpha=.4, axis=\"y\")  # 显示背景中的网格\n",
    "plt.gca().spines[\"top\"].set_alpha(.0)  # 让上方和右侧的坐标轴被隐藏\n",
    "plt.gca().spines[\"right\"].set_alpha(.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 或门、或门的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或门、或门的图像\n",
    "y_or = [0, 1, 1, 1]\n",
    "\n",
    "\n",
    "def OR(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.08  # 为了拟合不同的标签，重新定义一组w和b\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    y = (z >= 0).astype(int)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OR(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 绘制直线划分散点的图像\n",
    "x = np.arange(-1, 3, 0.5)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.title(\"OR GATE\", fontsize=16)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_or, cmap=\"rainbow\")\n",
    "plt.plot(x, (0.08-0.15*x)/0.15, color=\"k\", linestyle=\"--\")\n",
    "plt.xlim(-1, 3)\n",
    "plt.ylim(-1, 3)\n",
    "plt.grid(alpha=.4, axis=\"y\")\n",
    "plt.gca().spines[\"top\"].set_alpha(.0)\n",
    "plt.gca().spines[\"right\"].set_alpha(.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 非与门、非与门的图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_nand = [1, 1, 1, 0]\n",
    "\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    w1, w2, b = -0.15, -0.15, 0.23  # 同样为了拟合不同的标签，重新定义一组 w和b\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    y = [int(x) for x in z >= 0]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAND(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 图像\n",
    "x = np.arange(-1, 3, 0.5)\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.title(\"NAND GATE\", fontsize=16)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_nand, cmap=\"rainbow\")\n",
    "plt.plot(x, (0.23-0.15*x)/0.15, color=\"k\", linestyle=\"--\")\n",
    "plt.xlim(-1, 3)\n",
    "plt.ylim(-1, 3)\n",
    "plt.grid(alpha=.4, axis=\"y\")\n",
    "plt.gca().spines[\"top\"].set_alpha(.0)\n",
    "plt.gca().spines[\"right\"].set_alpha(.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### “异或门”（XOR GATE）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_xor = [0, 1, 1, 0]\n",
    "\n",
    "plt.figure(figsize=(5, 3))\n",
    "plt.title(\"XOR GATE\", fontsize=16)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_xor, cmap=\"rainbow\")\n",
    "plt.xlim(-1, 3)\n",
    "plt.ylim(-1, 3)\n",
    "plt.grid(alpha=.4, axis=\"y\")\n",
    "plt.gca().spines[\"top\"].set_alpha(.0)\n",
    "plt.gca().spines[\"right\"].set_alpha(.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XOR(x1, x2):\n",
    "    y_and = NAND(X[:, 0], X[:, 1])\n",
    "    y_or = OR(X[:, 0], X[:, 1])\n",
    "    y_and = AND(np.array(y_nand), np.array(y_or))\n",
    "    print(\"NAND:\",y_nand)\n",
    "    print(\"OR:\",y_or)\n",
    "    return y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAND: [1, 1, 1, 0]\n",
      "OR: [0 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 探索多层神经网络：层 vs h(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如果h(z)是线 性函数，或不存在，那增加再多的层也没有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回忆一下XOR数据的真实标签\n",
    "y_xor = [0, 1, 1, 0]\n",
    "\n",
    "\n",
    "def AND(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.23\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    # 下面这一行就是阶跃函数的表达式，注意AND函数是在输出层，所以保留输出层的阶跃函数g(z)\n",
    "    y = [int(x) for x in z >= 0]\n",
    "    return y\n",
    "\n",
    "\n",
    "def OR(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.08\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    # y = [int(x) for x in z >= 0] #注释掉阶跃函数，相当于h(z)是恒等函数\n",
    "    return z\n",
    "\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    w1, w2, b = -0.15, -0.15, 0.23\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    # y = [int(x) for x in z >= 0] #注释掉阶跃函数，相当于h(z)是恒等函数\n",
    "    return z\n",
    "\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    z_nand = NAND(X[:, 0], X[:, 1])\n",
    "    z_or = OR(X[:, 0], X[:, 1])\n",
    "    y_and = AND(np.array(z_nand), np.array(z_or))\n",
    "    return y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用sigmoid函数作为h(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据sigmoid公式定义sigmoid函数\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def AND_sigmoid(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.23\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    # AND函数是位于输出层的，这里是g(z)而非h(z)，因此不会受到将阶跃函数更换为sigmoid的影响\n",
    "    # g(z)依然是阶跃函数\n",
    "    y = [int(x) for x in z >= 0]\n",
    "    return y\n",
    "\n",
    "\n",
    "def OR_sigmoid(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.075\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    o = sigmoid(z)  # 这里是h(z)，我们使用sigmoid函数\n",
    "    return o\n",
    "\n",
    "\n",
    "def NAND_sigmoid(x1, x2):\n",
    "    w1, w2, b = -0.15, -0.15, 0.23\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    o = sigmoid(z)  # 这里是h(z)，我们使用sigmoid函数\n",
    "    return o\n",
    "\n",
    "\n",
    "def XOR_sigmoid(x1, x2):\n",
    "    o_nand = NAND_sigmoid(X[:, 0], X[:, 1])\n",
    "    o_or = OR_sigmoid(X[:, 0], X[:, 1])\n",
    "    y_and = AND_sigmoid(np.array(o_nand), np.array(o_or))\n",
    "    return y_and\n",
    "\n",
    "\n",
    "XOR_sigmoid(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即便是使用了非线性的 h(z)，也不一定能够解决非线性的问题。在不适合的非线性函 数加持下，神经网络的层数再多也无法起效。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### h(z) vs g(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果g(z)是sigmoid函数，而h(z)是阶跃函数\n",
    "\n",
    "# 根据sigmoid公式定义sigmoid函数\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def AND_sigmoid(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.23\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    o = sigmoid(z)  # 输出层是sigmoid函数\n",
    "    y = [int(x) for x in o >= 0.5]  # 按0.5为阈值将结果化为0和1\n",
    "    return o, y\n",
    "\n",
    "\n",
    "def OR(x1, x2):\n",
    "    w1, w2, b = 0.15, 0.15, -0.075\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    o = [int(x) for x in z >= 0]  # 这里是h(z)，我们使用阶跃函数\n",
    "    return o\n",
    "\n",
    "\n",
    "def NAND(x1, x2):\n",
    "    w1, w2, b = -0.15, -0.15, 0.23\n",
    "    z = x1*w1 + x2*w2 + b\n",
    "    o = [int(x) for x in z >= 0]  # 这里是h(z)，我们使用阶跃函数\n",
    "    return o\n",
    "\n",
    "\n",
    "def XOR(x1, x2):\n",
    "    o_nand = NAND(X[:, 0], X[:, 1])\n",
    "    o_or = OR(X[:, 0], X[:, 1])\n",
    "    y_and = AND_sigmoid(np.array(o_nand), np.array(o_or))\n",
    "    return y_and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.48001066, 0.51749286, 0.51749286, 0.48001066]), [0, 1, 1, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XOR(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 1, 0]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_xor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU & tanh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    import numpy as np\n",
    "    return np.maximum(0, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0. , 0. , 1. , 1.5])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu(np.array([-1, -0.4, 1, 1.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP多层感知机"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 隐藏层与神经元：重要参数hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 导入需要的数据和库，导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPClassifier as DNN\n",
    "from sklearn.model_selection import cross_val_score as cv\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from time import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 先使用机器学习中的数据来试试看神经网络的效果\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "y  # 二分类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 建模，使用交叉验证导出分数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9349945660611707"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = DNN(hidden_layer_sizes=(200,),\n",
    "          random_state=420  # random_state控制着神经网络上的某些随机性， 你能够猜到一些吗？\n",
    "          )\n",
    "# 这样，一个简单的神经网络就实例化完毕了\n",
    "cv(dnn, X, y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接口predict：预测出结果，由于之前在交叉验证中的训练不会被记录，因此需要重新训练\n",
    "dnn.fit(X, y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 5.80211596e-25],\n",
       "       [1.00000000e+00, 1.00641444e-14],\n",
       "       [9.99999999e-01, 6.28745603e-10],\n",
       "       ...,\n",
       "       [9.99497591e-01, 5.02409394e-04],\n",
       "       [1.00000000e+00, 2.79983276e-11],\n",
       "       [1.45552433e-01, 8.54447567e-01]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 接口predict_proba：返回预测的概率\n",
    "dnn.fit(X, y).predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9349945660611707\n",
      "1.201362133026123\n"
     ]
    }
   ],
   "source": [
    "# 看看运行时间如何\n",
    "times = time()\n",
    "dnn = DNN(hidden_layer_sizes=(200,), random_state=420)\n",
    "print(cv(dnn, X, y, cv=5).mean())\n",
    "print(time() - times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9613414066138798\n",
      "1.5502710342407227\n"
     ]
    }
   ],
   "source": [
    "# 使用随机森林进行一个对比\n",
    "times = time()\n",
    "clf_rfc = RFC(n_estimators=200, random_state=420)\n",
    "print(cv(clf_rfc, X, y, cv=5).mean())\n",
    "print(time() - times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 使用参数hidden_layer_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934979040521658\n",
      "1.0657610893249512\n"
     ]
    }
   ],
   "source": [
    "times = time()\n",
    "dnn = DNN(hidden_layer_sizes=(50), random_state=420)\n",
    "print(cv(dnn, X, y, cv=5).mean())\n",
    "print(time() - times)\n",
    "# 试试看不用的神经元个数组合：(50,50),(50,100),(100,50),(100,100,100)\n",
    "# 不断调整hidden_layer_sizes中输入的内容，你发现了什么？\n",
    "# 来试试看，(70,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用重要属性n_layers_，显示神经网络的层数\n",
    "dnn.fit(X, y).n_layers_\n",
    "# 这里返回的层数将输入层和输出层也考虑在其中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重要属性classes_，查看返回结果中一共有多少个类别\n",
    "dnn.fit(X, y).classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重要属性n_outputs_，显示输出层上神经元的个数（即输出结果的个数）\n",
    "# 试想下二分类神经网络对应的g(z)和我们之前总结的规律，应该很容易就能够判断这里会 输出几\n",
    "dnn.fit(X, y).n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cool/.pyenv/versions/3.8.5/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果更换数据，n_outputs会返回多少？\n",
    "from sklearn.datasets import load_digits\n",
    "dnn.fit(load_digits().data, load_digits().target).n_outputs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(load_digits().target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 提升神经网络效果的有效方法：归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_ = SS().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9806862288464524\n",
      "2.1518898010253906\n"
     ]
    }
   ],
   "source": [
    "times = time()\n",
    "dnn = DNN(hidden_layer_sizes=(200, 50), random_state=420)\n",
    "print(cv(dnn, X_, y, cv=5).mean())\n",
    "print(time() - times)\n",
    "# 最终的结果显示，(200,50)是一个比较有效的组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 激活函数：重要参数activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "identity 0.9613724576929048\n",
      "2.007845163345337\n",
      "logistic 0.9666356155876418\n",
      "7.091061115264893\n",
      "tanh 0.9754385964912281\n",
      "3.5398380756378174\n",
      "relu 0.9806862288464524\n",
      "1.9739201068878174\n"
     ]
    }
   ],
   "source": [
    "for activef in ['identity', 'logistic', 'tanh', 'relu']:\n",
    "    times = time()\n",
    "    dnn = DNN(hidden_layer_sizes=(200, 50),\n",
    "              activation=activef,\n",
    "              max_iter=2000,\n",
    "              random_state=420\n",
    "              )\n",
    "    print(activef, cv(dnn, X_, y, cv=5).mean())\n",
    "    print(time() - times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logistic'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重要属性out_activation_，猜猜它会返回什么内容？\n",
    "\n",
    "dnn.fit(X, y).out_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softmax'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果更换数据，out_activation_会返回什么结果？\n",
    "\n",
    "dnn.fit(load_digits().data, load_digits().target).out_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 很明显，属性out_activation_返回的是g(z)，而参数activation控制的是h(z)。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络学习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络学习的基本思想"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adam 0.9806862288464524\n",
      "1.9451310634613037\n",
      "lbfgs 0.9648967551622419\n",
      "0.5077519416809082\n",
      "sgd 0.9736531594472908\n",
      "5.633463144302368\n"
     ]
    }
   ],
   "source": [
    "for solver_ in ['adam', 'lbfgs', 'sgd']:\n",
    "    times = time()\n",
    "    dnn = DNN(hidden_layer_sizes=(200, 50),\n",
    "              solver=solver_,\n",
    "              activation='relu',\n",
    "              max_iter=2000,  # 如果设置较小的max_iter会发生什么？\n",
    "              random_state=420\n",
    "              )\n",
    "    print(solver_, cv(dnn, X_, y, cv=5).mean())\n",
    "    print(time() - times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mini-batch SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 看看乳腺癌数据集的结构，注意到这是一个非常小的数据集\n",
    "\n",
    "X_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 建立神经网络\n",
    "dnn = DNN(hidden_layer_sizes=(20,),\n",
    "          activation='relu',\n",
    "          batch_size=20,  # 批量大小N_B\n",
    "          shuffle=True,  # 是否随机选取\n",
    "          max_iter=500,  # 从参数的样子来看是最大迭代次数的意思，和逻辑回归中 相似，暂时不用去管\n",
    "          random_state=420\n",
    "          )\n",
    "dnn = dnn.fit(X_, y)\n",
    "\n",
    "# 接口score\n",
    "dnn.score(X_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "237"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 重要属性n_iter_\n",
    "# 注意，只有训练完毕的模型才存在该属性，使用交叉验证时无法获取模型的实际迭代次数\n",
    "\n",
    "dnn.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 450\n",
      "\t time: 00:01:287731\n",
      "\t cv value: 0.9771619313771154 4.892292503671222e-05\n",
      "\n",
      "batch_size: 200\n",
      "\t time: 00:02:156664\n",
      "\t cv value: 0.9789318428815401 7.964425808976153e-05\n",
      "\n",
      "batch_size: 50\n",
      "\t time: 00:04:286932\n",
      "\t cv value: 0.9753764943331781 4.4413022160158524e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 试试看不同batch_size下的测试分数结果\n",
    "for size in [450, 200, 50]:\n",
    "    dnn = DNN(hidden_layer_sizes=(20,),\n",
    "              activation='relu',\n",
    "              batch_size=size,  # 批量大小N_B\n",
    "              shuffle=True,  # 是否随机选取\n",
    "              max_iter=500,  # 从参数的样子来看是最大迭代次数的意思，和逻辑回归中 相似，暂时不用去管\n",
    "              random_state=420\n",
    "              )\n",
    "    times = time()\n",
    "    cvresult = cv(dnn, X_, y, cv=5)  # 交叉验证\n",
    "    usedtime = time() - times\n",
    "    acc, var = cvresult.mean(), cvresult.var()\n",
    "    print(\"batch_size:\", size)\n",
    "    print(\"\\t time:\", datetime.datetime.fromtimestamp(\n",
    "        usedtime).strftime(\"%M:%S:%f\"))\n",
    "    print(\"\\t cv value:\", acc, var)  # 返回交叉验证的均值和方差\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 更换成更大的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入神经网络入门数据MNIST \n",
    "#这是手写数字数据集，我们以前经常使用的sklearn中的load_digits就是从MNIST中 提取出来的1700多条数据\n",
    "data = pd.read_csv('./mnist-in-csv/mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 785)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>1x1</th>\n",
       "      <th>1x2</th>\n",
       "      <th>1x3</th>\n",
       "      <th>1x4</th>\n",
       "      <th>1x5</th>\n",
       "      <th>1x6</th>\n",
       "      <th>1x7</th>\n",
       "      <th>1x8</th>\n",
       "      <th>1x9</th>\n",
       "      <th>...</th>\n",
       "      <th>28x19</th>\n",
       "      <th>28x20</th>\n",
       "      <th>28x21</th>\n",
       "      <th>28x22</th>\n",
       "      <th>28x23</th>\n",
       "      <th>28x24</th>\n",
       "      <th>28x25</th>\n",
       "      <th>28x26</th>\n",
       "      <th>28x27</th>\n",
       "      <th>28x28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  1x1  1x2  1x3  1x4  1x5  1x6  1x7  1x8  1x9  ...  28x19  28x20  \\\n",
       "0      5    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "1      0    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "2      4    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "3      1    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "4      9    0    0    0    0    0    0    0    0    0  ...      0      0   \n",
       "\n",
       "   28x21  28x22  28x23  28x24  28x25  28x26  28x27  28x28  \n",
       "0      0      0      0      0      0      0      0      0  \n",
       "1      0      0      0      0      0      0      0      0  \n",
       "2      0      0      0      0      0      0      0      0  \n",
       "3      0      0      0      0      0      0      0      0  \n",
       "4      0      0      0      0      0      0      0      0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "datay = data.iloc[:, 0]\n",
    "datax = data.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler as SS\n",
    "datax_ = SS().fit_transform(datax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 60000\n",
      "\t time: 10:39:177924\n",
      "\t acc: 0.9646333333333333\n",
      "\t actual iter: 774\n",
      "\t actual seen data amount: 46440000\n",
      "\n",
      "batch_size: 10000\n",
      "\t time: 09:24:239203\n",
      "\t acc: 0.99535\n",
      "\t actual iter: 689\n",
      "\t actual seen data amount: 6890000\n",
      "\n",
      "batch_size: 5000\n",
      "\t time: 08:18:141077\n",
      "\t acc: 0.9996333333333334\n",
      "\t actual iter: 613\n",
      "\t actual seen data amount: 3065000\n",
      "\n",
      "batch_size: 1000\n",
      "\t time: 04:55:844825\n",
      "\t acc: 0.9999166666666667\n",
      "\t actual iter: 335\n",
      "\t actual seen data amount: 335000\n",
      "\n",
      "batch_size: 200\n",
      "\t time: 04:04:480439\n",
      "\t acc: 0.99995\n",
      "\t actual iter: 243\n",
      "\t actual seen data amount: 48600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 在该数据集的基础上，建立不同batch_size的神经网络\n",
    "for size in [60000, 10000, 5000, 1000, 200]:\n",
    "    dnn = DNN(hidden_layer_sizes=(20,),\n",
    "              activation='relu',\n",
    "              batch_size=size,  # 批量大小N_B\n",
    "              max_iter=3000,\n",
    "              random_state=420\n",
    "              )\n",
    "    times = time()\n",
    "    model = dnn.fit(datax_, datay)  # 为了更快的计算速度而不使用交叉验证\n",
    "    result = model.score(datax_, datay)\n",
    "    print(\"batch_size:\", size)\n",
    "    print(\"\\t time:\", datetime.datetime.fromtimestamp(\n",
    "        time() - times).strftime(\"%M:%S:%f\"))  # 运行时间\n",
    "    print(\"\\t acc:\", result)  # 运行结果\n",
    "    print(\"\\t actual iter:\", model.n_iter_)  # 在这里由于没有使用交叉验证，可以查看模型实际的迭代次数\n",
    "    # 迭代次数*每次迭代时使用的数据，就可以看到真实的“算法遍历了多少数据”\n",
    "    print(\"\\t actual seen data amount:\", model.n_iter_ * size)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络的学习流程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一轮迭代：全数据，小批量，epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 450\n",
      "\t time: 00:01:275362\n",
      "\t cv value: 0.9771619313771154 4.892292503671222e-05\n",
      "\t 完成一个epoch所需要的迭代次数: 1.0115555555555558\n",
      "\n",
      "batch_size: 200\n",
      "\t time: 00:02:191194\n",
      "\t cv value: 0.9789318428815401 7.964425808976153e-05\n",
      "\t 完成一个epoch所需要的迭代次数: 2.2760000000000002\n",
      "\n",
      "batch_size: 50\n",
      "\t time: 00:04:356731\n",
      "\t cv value: 0.9753764943331781 4.4413022160158524e-05\n",
      "\t 完成一个epoch所需要的迭代次数: 9.104000000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for size in [450, 200, 50]:\n",
    "    dnn = DNN(hidden_layer_sizes=(20,),\n",
    "              activation='relu',\n",
    "              batch_size=size,  # 批量大小N_B\n",
    "              max_iter=500,\n",
    "              random_state=420\n",
    "              )\n",
    "    times = time()\n",
    "    cvresult = cv(dnn, X_, y, cv=5)\n",
    "    usedtime = time() - times\n",
    "    acc, var = cvresult.mean(), cvresult.var()\n",
    "    print(\"batch_size:\", size)\n",
    "    print(\"\\t time:\", datetime.datetime.fromtimestamp(\n",
    "        usedtime).strftime(\"%M:%S:%f\"))  # 运行时间\n",
    "    print(\"\\t cv value:\", acc, var)  # 返回交叉验证的均值和方差\n",
    "    print(\"\\t 完成一个epoch所需要的迭代次数:\", X_.shape[0]*0.8/size)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cool/.pyenv/versions/3.8.5/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 450\n",
      "\t time: 00:00:184113\n",
      "\t result: 0.9894551845342706\n",
      "\t actual iter: 200\n",
      "\t 完成一个epoch所需要的迭代次数: 1.0115555555555558\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cool/.pyenv/versions/3.8.5/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size: 200\n",
      "\t time: 00:00:238927\n",
      "\t result: 0.9929701230228472\n",
      "\t actual iter: 200\n",
      "\t 完成一个epoch所需要的迭代次数: 2.2760000000000002\n",
      "\n",
      "batch_size: 50\n",
      "\t time: 00:00:723968\n",
      "\t result: 0.9929701230228472\n",
      "\t actual iter: 200\n",
      "\t 完成一个epoch所需要的迭代次数: 9.104000000000001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cool/.pyenv/versions/3.8.5/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for size in [450, 200, 50]:\n",
    "    dnn = DNN(hidden_layer_sizes=(20,),\n",
    "              activation='relu',\n",
    "              batch_size=size,  # 批量大小N_B\n",
    "              max_iter=200,\n",
    "              random_state=420\n",
    "              )\n",
    "    times = time()\n",
    "    dnn = dnn.fit(X_, y)  # 为了调用真实的n_iter所以不使用交叉验证\n",
    "    usedtime = time() - times\n",
    "    print(\"batch_size:\", size)\n",
    "    print(\"\\t time:\", datetime.datetime.fromtimestamp(\n",
    "        usedtime).strftime(\"%M:%S:%f\"))  # 运行时间\n",
    "    print(\"\\t result:\", dnn.score(X_, y))  # 返回结果\n",
    "    print(\"\\t actual iter:\", dnn.n_iter_)  # 调用实际的迭代次数\n",
    "    print(\"\\t 完成一个epoch所需要的迭代次数:\", X_.shape[0]*0.8/size)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 第一轮迭代：学习率与学习率的调整"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 学习率衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 \teta: 0.1\n",
      "iter: 2 \teta: 0.08705505632961241\n",
      "iter: 5 \teta: 0.07247796636776956\n",
      "iter: 10 \teta: 0.06309573444801933\n",
      "iter: 20 \teta: 0.05492802716530589\n"
     ]
    }
   ],
   "source": [
    "for t in [1, 2, 5, 10, 20]:  # t是迭代次数\n",
    "    eta0, power_t = 0.1, 0.2  # 可以试着更换一下原始的eta0和设置的衰减用指数\n",
    "    eta = eta0/np.power(t, power_t)\n",
    "    print('iter:', t, '\\teta:', eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 自适应学习率调整"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta_strategy: constant\n",
      "\t time: 00:00:343704\n",
      "\t cv value: 0.9736376339077782 3.0787378664389295e-05\n",
      "\n",
      "eta_strategy: invscaling\n",
      "\t time: 00:00:531842\n",
      "\t cv value: 0.9754075454122031 4.265823365447623e-05\n",
      "\n",
      "eta_strategy: adaptive\n",
      "\t time: 00:00:834964\n",
      "\t cv value: 0.9736376339077782 3.0787378664389295e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for eta_strategy in ['constant', 'invscaling', 'adaptive']:\n",
    "    dnn = DNN(hidden_layer_sizes=(20,),\n",
    "              activation='relu',\n",
    "              solver='sgd',\n",
    "              learning_rate_init=0.5,  # 初始学习率\n",
    "              learning_rate=eta_strategy,  # 学习率的变化策略\n",
    "              power_t=0.1,  # 衰减指数\n",
    "              batch_size=200,\n",
    "              max_iter=3000,\n",
    "              random_state=420\n",
    "              )\n",
    "    times = time()\n",
    "    cvresult = cv(dnn, X_, y, cv=5)\n",
    "    usedtime = time() - times\n",
    "    acc, var = cvresult.mean(), cvresult.var()\n",
    "    print(\"eta_strategy:\", eta_strategy)\n",
    "    print(\"\\t time:\", datetime.datetime.fromtimestamp(\n",
    "        usedtime).strftime(\"%M:%S:%f\"))  # 运行时间\n",
    "    print(\"\\t cv value:\", acc, var)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2760000000000002\n",
      "Iteration 1, loss = 0.40927842\n",
      "Iteration 2, loss = 0.11355190\n",
      "Iteration 3, loss = 0.06903990\n",
      "Iteration 4, loss = 0.05962010\n",
      "Iteration 5, loss = 0.05282566\n",
      "Iteration 6, loss = 0.04439347\n",
      "Iteration 7, loss = 0.03777019\n",
      "Iteration 8, loss = 0.03430887\n",
      "Iteration 9, loss = 0.03915498\n",
      "Iteration 10, loss = 0.02625859\n",
      "Iteration 11, loss = 0.02301228\n",
      "Iteration 12, loss = 0.02062814\n",
      "Iteration 13, loss = 0.01939899\n",
      "Iteration 14, loss = 0.01822174\n",
      "Iteration 15, loss = 0.01640199\n",
      "Iteration 16, loss = 0.01585494\n",
      "Iteration 17, loss = 0.01446319\n",
      "Iteration 18, loss = 0.01413215\n",
      "Iteration 19, loss = 0.01361747\n",
      "Iteration 20, loss = 0.01231684\n",
      "Iteration 21, loss = 0.01230287\n",
      "Iteration 22, loss = 0.01287507\n",
      "Iteration 23, loss = 0.01091168\n",
      "Iteration 24, loss = 0.01079219\n",
      "Iteration 25, loss = 0.01149510\n",
      "Iteration 26, loss = 0.00959888\n",
      "Iteration 27, loss = 0.00922374\n",
      "Iteration 28, loss = 0.00929903\n",
      "Iteration 29, loss = 0.00861801\n",
      "Iteration 30, loss = 0.00765946\n",
      "Iteration 31, loss = 0.00784510\n",
      "Iteration 32, loss = 0.00742281\n",
      "Iteration 33, loss = 0.00813189\n",
      "Iteration 34, loss = 0.00672897\n",
      "Iteration 35, loss = 0.00654196\n",
      "Iteration 36, loss = 0.00698488\n",
      "Iteration 37, loss = 0.00645903\n",
      "Iteration 38, loss = 0.00628378\n",
      "Iteration 39, loss = 0.00558154\n",
      "Iteration 40, loss = 0.00532418\n",
      "Iteration 41, loss = 0.00523431\n",
      "Iteration 42, loss = 0.00537215\n",
      "Iteration 43, loss = 0.00508703\n",
      "Iteration 44, loss = 0.00469617\n",
      "Iteration 45, loss = 0.00462512\n",
      "Iteration 46, loss = 0.00440572\n",
      "Iteration 47, loss = 0.00443804\n",
      "Iteration 48, loss = 0.00434195\n",
      "Iteration 49, loss = 0.00431392\n",
      "Iteration 50, loss = 0.00435148\n",
      "Iteration 51, loss = 0.00396748\n",
      "Iteration 52, loss = 0.00413501\n",
      "Iteration 53, loss = 0.00426411\n",
      "Iteration 54, loss = 0.00389054\n",
      "Iteration 55, loss = 0.00346937\n",
      "Iteration 56, loss = 0.00388288\n",
      "Iteration 57, loss = 0.00334606\n",
      "Iteration 58, loss = 0.00337535\n",
      "Iteration 59, loss = 0.00330898\n",
      "Iteration 60, loss = 0.00315367\n",
      "Iteration 61, loss = 0.00301716\n",
      "Iteration 62, loss = 0.00308186\n",
      "Iteration 63, loss = 0.00313218\n",
      "Iteration 64, loss = 0.00276555\n",
      "Iteration 65, loss = 0.00278059\n",
      "Iteration 66, loss = 0.00270048\n",
      "Iteration 67, loss = 0.00268588\n",
      "Iteration 68, loss = 0.00274110\n",
      "Iteration 69, loss = 0.00270697\n",
      "Iteration 70, loss = 0.00249026\n",
      "Iteration 71, loss = 0.00268520\n",
      "Iteration 72, loss = 0.00241956\n",
      "Iteration 73, loss = 0.00233597\n",
      "Iteration 74, loss = 0.00241198\n",
      "Iteration 75, loss = 0.00229508\n",
      "Iteration 76, loss = 0.00224988\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.100000\n",
      "Iteration 77, loss = 0.00214717\n",
      "Iteration 78, loss = 0.00211508\n",
      "Iteration 79, loss = 0.00210587\n",
      "Iteration 80, loss = 0.00207809\n",
      "Iteration 81, loss = 0.00206661\n",
      "Iteration 82, loss = 0.00204386\n",
      "Iteration 83, loss = 0.00204833\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.020000\n",
      "Iteration 84, loss = 0.00201429\n",
      "Iteration 85, loss = 0.00200367\n",
      "Iteration 86, loss = 0.00200221\n",
      "Iteration 87, loss = 0.00199352\n",
      "Iteration 88, loss = 0.00199256\n",
      "Iteration 89, loss = 0.00198806\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.004000\n",
      "Iteration 90, loss = 0.00198418\n",
      "Iteration 91, loss = 0.00198078\n",
      "Iteration 92, loss = 0.00197911\n",
      "Iteration 93, loss = 0.00197725\n",
      "Iteration 94, loss = 0.00197604\n",
      "Iteration 95, loss = 0.00197623\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.000800\n",
      "Iteration 96, loss = 0.00197442\n",
      "Iteration 97, loss = 0.00197408\n",
      "Iteration 98, loss = 0.00197371\n",
      "Iteration 99, loss = 0.00197328\n",
      "Iteration 100, loss = 0.00197310\n",
      "Iteration 101, loss = 0.00197303\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.000160\n",
      "Iteration 102, loss = 0.00197262\n",
      "Iteration 103, loss = 0.00197248\n",
      "Iteration 104, loss = 0.00197248\n",
      "Iteration 105, loss = 0.00197236\n",
      "Iteration 106, loss = 0.00197232\n",
      "Iteration 107, loss = 0.00197226\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.000032\n",
      "Iteration 108, loss = 0.00197219\n",
      "Iteration 109, loss = 0.00197219\n",
      "Iteration 110, loss = 0.00197217\n",
      "Iteration 111, loss = 0.00197217\n",
      "Iteration 112, loss = 0.00197216\n",
      "Iteration 113, loss = 0.00197214\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.000006\n",
      "Iteration 114, loss = 0.00197213\n",
      "Iteration 115, loss = 0.00197213\n",
      "Iteration 116, loss = 0.00197212\n",
      "Iteration 117, loss = 0.00197212\n",
      "Iteration 118, loss = 0.00197211\n",
      "Iteration 119, loss = 0.00197211\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.000001\n",
      "Iteration 120, loss = 0.00197211\n",
      "Iteration 121, loss = 0.00197211\n",
      "Iteration 122, loss = 0.00197211\n",
      "Iteration 123, loss = 0.00197210\n",
      "Iteration 124, loss = 0.00197210\n",
      "Iteration 125, loss = 0.00197210\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 126, loss = 0.00197210\n",
      "Iteration 127, loss = 0.00197210\n",
      "Iteration 128, loss = 0.00197210\n",
      "Iteration 129, loss = 0.00197210\n",
      "Iteration 130, loss = 0.00197210\n",
      "Iteration 131, loss = 0.00197210\n",
      "Training loss did not improve more than tol=0.000100 for 5 consecutive epochs. Learning rate too small. Stopping.\n",
      "eta_strategy:adaptive\n",
      "\t time: 00:00:175174\n",
      "\t score: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 完成一次epoch所需要的迭代次数\n",
    "iter_ = X_.shape[0]*0.8/200\n",
    "print(iter_)\n",
    "\n",
    "dnn = DNN(hidden_layer_sizes=(20,),\n",
    "          activation='relu',\n",
    "          solver='sgd',\n",
    "          learning_rate_init=0.5,  # 初始学习率\n",
    "          learning_rate='adaptive',  # 学习率的变化策略\n",
    "          n_iter_no_change=5,  # 设定允许的最大无效epochs为5\n",
    "          verbose=True,\n",
    "          batch_size=200,\n",
    "          max_iter=3000,\n",
    "          random_state=420\n",
    "          )\n",
    "\n",
    "times = time()\n",
    "dnn = dnn.fit(X_, y)\n",
    "usedtime = time() - times\n",
    "print(\"eta_strategy:adaptive\")\n",
    "print(\"\\t time:\", datetime.datetime.fromtimestamp(\n",
    "    usedtime).strftime(\"%M:%S:%f\"))\n",
    "print(\"\\t score:\", dnn.score(X_, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 从第一轮迭代到第t轮迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-4.17596414e-01, -1.48419775e-01, -4.29184936e-01,\n",
       "         -7.43552173e-01,  3.83854177e-01, -7.97619100e-01,\n",
       "         -1.56208474e-01, -4.90088320e-01,  4.31618493e-01,\n",
       "         -3.70042612e-01, -2.01993585e-01,  2.23947270e-01,\n",
       "         -9.01819245e-01, -4.53543039e-01,  8.34168792e-01,\n",
       "         -2.93744433e-01, -1.86687185e-01, -1.06768466e-01,\n",
       "         -6.99340520e-02,  1.32475943e-01],\n",
       "        [ 6.85512118e-02, -3.41560979e-01, -6.94878193e-02,\n",
       "         -1.60544036e-01, -1.41115249e+00, -5.62433321e-01,\n",
       "         -2.77367862e-01, -1.52279757e-01,  1.44854630e-01,\n",
       "         -7.30926154e-02, -4.63730885e-01,  4.03432318e-01,\n",
       "         -9.40562232e-03, -1.47364860e-01,  6.99654175e-01,\n",
       "          1.70161828e-01,  3.56157944e-01, -3.09518618e-01,\n",
       "         -4.00990898e-01, -6.57836591e-03],\n",
       "        [-1.60932508e-01, -2.51548172e-01, -7.60034201e-02,\n",
       "         -4.35258080e-01, -1.69072118e-01, -6.35916221e-01,\n",
       "         -1.59900703e-01, -1.50802286e-01,  5.60704335e-01,\n",
       "         -1.76861870e-01,  1.82331053e-01,  2.90209568e-01,\n",
       "         -5.93738712e-01, -4.02845222e-01,  6.88327502e-01,\n",
       "          8.40444854e-02, -2.58416964e-01, -4.33065078e-01,\n",
       "         -9.22183331e-02, -4.16139631e-01],\n",
       "        [-7.62840665e-02, -2.94333142e-01, -5.65647841e-01,\n",
       "         -3.84838211e-01, -1.26877430e-01, -1.07348584e+00,\n",
       "         -3.85469953e-02, -5.10165131e-01,  1.64107969e-01,\n",
       "         -6.44107623e-01, -3.16171875e-02,  5.03896662e-01,\n",
       "         -9.46539199e-01, -2.34486860e-01,  4.50634882e-01,\n",
       "         -9.73050275e-02, -1.71490784e-01, -1.44173308e-01,\n",
       "         -3.35449533e-01, -9.95447114e-02],\n",
       "        [ 3.62695432e-01, -4.05797217e-01, -7.89569090e-02,\n",
       "         -1.15452434e-01,  3.91607309e-01, -1.62655734e-01,\n",
       "         -1.25230119e-01, -5.01596672e-01,  2.03315245e-01,\n",
       "         -1.46150502e-01,  2.15130588e-01,  5.28031108e-01,\n",
       "         -5.56423949e-01,  2.48707260e-01,  3.38833338e-01,\n",
       "         -1.89774191e-01,  6.97810866e-02,  9.48573744e-02,\n",
       "         -2.65693737e-01, -4.39601871e-01],\n",
       "        [ 1.27979840e-01, -6.01506156e-02, -2.60037596e-01,\n",
       "         -8.45306901e-01,  2.10293727e-01, -9.57099630e-01,\n",
       "         -6.23815866e-02,  1.05396001e-01, -7.93549992e-02,\n",
       "          2.06523028e-02,  5.46424142e-02,  6.01397946e-01,\n",
       "         -9.51493063e-01, -6.97345581e-01,  2.60783932e-01,\n",
       "          2.75972135e-01,  2.14116181e-02, -2.50009724e-01,\n",
       "         -1.47705972e-01,  3.96092021e-01],\n",
       "        [ 5.37708794e-02, -2.69357445e-01, -8.25995263e-02,\n",
       "         -1.00210373e-01, -4.12903255e-01, -6.43231091e-01,\n",
       "         -4.26540003e-01, -5.06999274e-01,  2.82900501e-01,\n",
       "         -4.95682146e-01,  3.98748519e-01,  5.18609702e-01,\n",
       "         -4.99478687e-01, -4.73183787e-01,  9.10298075e-01,\n",
       "         -8.89632442e-02, -4.21649298e-03, -4.21886525e-02,\n",
       "         -6.30012161e-01, -8.97341484e-02],\n",
       "        [-5.78171961e-01, -2.69299772e-01, -5.12308962e-01,\n",
       "         -9.62079201e-02, -4.93945423e-01, -1.08233942e+00,\n",
       "         -3.28454659e-01, -5.42472166e-01,  5.48341710e-01,\n",
       "         -5.91611124e-01,  4.04046841e-01,  5.46350892e-01,\n",
       "         -3.67147119e-01, -2.70345822e-01,  8.69737075e-01,\n",
       "         -1.80683539e-01, -2.45594830e-01, -4.68222713e-02,\n",
       "         -1.90279956e-01, -3.18590946e-01],\n",
       "        [-9.51928489e-02,  3.56443514e-01, -6.84509242e-02,\n",
       "          1.09166572e-02, -1.86201446e-01, -1.44382581e-01,\n",
       "         -2.20040070e-01, -1.66811619e-02, -2.81989808e-01,\n",
       "          5.73528381e-01,  6.23563429e-02,  5.06538779e-01,\n",
       "         -9.75586418e-02, -3.26345805e-01,  1.97693276e-01,\n",
       "         -8.58140056e-03, -1.20938286e-01,  1.15857735e-01,\n",
       "         -1.37088887e-01, -4.43852785e-02],\n",
       "        [-1.30326202e-02, -9.50873289e-02,  2.81397826e-01,\n",
       "         -2.56027599e-01, -3.37970417e-01,  7.53986923e-02,\n",
       "          1.71669069e-02, -1.15815232e-01, -4.25203268e-01,\n",
       "          3.39836898e-02,  8.04844558e-02, -7.62392867e-01,\n",
       "         -1.35383949e-01,  1.77059815e-02, -1.65513950e-01,\n",
       "          1.03145190e-01, -4.78971055e-01,  9.49652523e-02,\n",
       "          1.55347799e-01,  2.99387772e-01],\n",
       "        [-3.75392669e-02, -9.22253620e-02,  1.86963689e-01,\n",
       "         -7.00392400e-02, -4.64553651e-01, -4.29544114e-01,\n",
       "         -4.98329493e-01, -3.31188794e-01, -2.48947742e-02,\n",
       "         -6.23773590e-01,  4.03859796e-01,  3.27990427e-01,\n",
       "         -3.37872055e-01,  2.64461315e-01,  7.25929307e-01,\n",
       "          3.24402961e-01, -7.44975368e-01,  2.02805490e-01,\n",
       "         -3.18604170e-01, -3.77682878e-01],\n",
       "        [ 3.98643928e-02,  1.60781733e-01, -2.84642002e-01,\n",
       "          1.61672496e-01, -5.99944514e-01, -4.36741403e-01,\n",
       "          1.52604988e-01, -9.08880448e-03, -1.78311684e-01,\n",
       "         -1.62029133e-01, -2.80852522e-01, -2.40369697e-01,\n",
       "          1.59211962e-01, -4.67389802e-01, -3.08948049e-01,\n",
       "          2.15804779e-01,  1.67104884e-01, -2.71148500e-01,\n",
       "          3.67331124e-01,  5.10189027e-02],\n",
       "        [-2.99887575e-01, -1.36418151e-01, -1.74695185e-01,\n",
       "          1.41616632e-01, -3.34547330e-01, -3.19572004e-01,\n",
       "         -2.11067415e-01, -2.62933807e-01, -1.39655199e-01,\n",
       "         -5.49345222e-01,  1.44731634e-01,  6.08331985e-01,\n",
       "         -7.34803868e-01, -7.38113587e-02,  4.25251359e-01,\n",
       "          2.08590638e-01, -4.42909975e-01,  4.66078236e-02,\n",
       "         -2.99215446e-01, -4.26345169e-01],\n",
       "        [-2.86627118e-01,  8.14054668e-02,  4.80528380e-02,\n",
       "         -2.66759950e-02, -7.58397208e-01, -7.47404540e-01,\n",
       "         -1.42599622e-01, -5.67100978e-01,  2.43521615e-01,\n",
       "         -4.55002354e-01, -2.24112956e-01,  7.75770368e-01,\n",
       "         -3.04088816e-01,  2.19091689e-01,  8.87623651e-01,\n",
       "          1.13047090e-01, -1.69814586e-01,  2.06983775e-01,\n",
       "         -6.06368024e-01, -3.26091918e-01],\n",
       "        [ 2.63111861e-01, -2.62910144e-01, -3.85434017e-01,\n",
       "          1.03724914e-01,  3.16973382e-01,  4.21762687e-02,\n",
       "          3.91280865e-01, -1.36287219e-01,  3.80465573e-01,\n",
       "          2.67267778e-01, -1.53798847e-01, -2.16549432e-01,\n",
       "          3.62369337e-01, -4.43275538e-01, -3.29933936e-01,\n",
       "          8.47618099e-02, -4.21639567e-02,  1.81044061e-01,\n",
       "         -2.37363778e-01, -2.72288421e-01],\n",
       "        [-1.24705891e-01,  2.31885376e-01, -1.06158166e-01,\n",
       "         -3.10245260e-01,  6.48191199e-01, -7.04147727e-01,\n",
       "         -1.26229506e-01,  4.48475993e-01, -2.72368227e-01,\n",
       "          3.33969249e-01, -1.22203982e-01, -3.09335999e-01,\n",
       "         -5.55201336e-01, -7.50895292e-01, -4.98198336e-01,\n",
       "         -1.66159354e-01,  6.01450472e-01, -6.78586974e-02,\n",
       "          1.08190709e-01,  7.11820307e-01],\n",
       "        [-1.32910443e-01, -1.49274736e-01, -2.10828410e-01,\n",
       "         -3.40610229e-01, -7.91990476e-02, -4.04203561e-01,\n",
       "         -1.57778423e-01,  9.06773828e-02,  2.08015716e-01,\n",
       "          1.49001402e-01, -4.12381738e-01, -1.23466677e-03,\n",
       "          7.18911100e-02, -4.28659835e-03, -1.68269061e-01,\n",
       "          1.60747353e-01, -3.75096654e-01,  1.25835528e-01,\n",
       "         -2.04872406e-02, -7.98131740e-02],\n",
       "        [-1.18350641e-01,  2.47867264e-01, -1.86504382e-02,\n",
       "          2.16781611e-01, -5.58603348e-01, -3.59786204e-01,\n",
       "         -4.90266479e-01, -4.28159422e-01,  1.97734933e-01,\n",
       "         -4.20180522e-01, -6.71115015e-02,  1.68842266e-01,\n",
       "         -3.01296877e-01, -2.28962517e-01, -1.77575179e-01,\n",
       "          3.29373224e-01, -3.42122929e-01, -2.22602251e-01,\n",
       "         -1.27874413e-01, -9.11598215e-02],\n",
       "        [-1.81347204e-01, -1.70786917e-01, -2.04826776e-01,\n",
       "         -8.38216206e-02,  1.66143369e-01, -4.05789381e-01,\n",
       "          4.68106065e-01,  1.28910891e-01, -3.34040772e-01,\n",
       "          1.29057729e-01, -1.55271486e-01,  5.98050187e-01,\n",
       "          7.03483384e-02, -3.62398625e-01, -4.44994205e-01,\n",
       "          1.69305842e-01,  1.17020808e-01,  1.18582683e-01,\n",
       "          2.93202935e-01, -8.33342642e-02],\n",
       "        [ 8.66722010e-02,  2.90985689e-01, -3.58588543e-01,\n",
       "         -3.67570850e-01,  4.59538737e-02,  2.35672559e-01,\n",
       "          2.26712516e-01,  5.96592790e-01,  2.87185549e-02,\n",
       "          1.15507667e-01, -1.58299101e-01, -5.97336580e-01,\n",
       "          2.91671630e-02,  2.89722886e-02, -7.82765121e-01,\n",
       "         -3.65544529e-01,  7.54503228e-02,  9.07621998e-02,\n",
       "         -2.21526860e-02,  3.99454697e-01],\n",
       "        [-1.01846057e-01, -5.25778786e-01, -4.99429155e-01,\n",
       "         -6.03540740e-01, -4.32104791e-01, -4.95927707e-01,\n",
       "         -1.99053486e-01, -3.44807934e-01,  5.93582655e-01,\n",
       "         -3.10980024e-01,  2.77749127e-01,  5.41305236e-01,\n",
       "         -7.89050138e-01,  2.25925108e-02,  1.04898839e+00,\n",
       "          5.26221172e-02, -4.33649940e-01,  1.14007663e-01,\n",
       "         -5.58068667e-01, -7.74830080e-01],\n",
       "        [-3.49118665e-01, -4.32247641e-01, -1.42290610e-01,\n",
       "          2.98625065e-01, -9.67447340e-01, -4.88734682e-01,\n",
       "         -1.78478890e-01, -3.23327952e-02,  1.52821780e-01,\n",
       "          2.03506495e-02,  2.72715475e-02,  7.39268411e-01,\n",
       "         -1.84392641e-01,  8.32997437e-02,  5.28400499e-01,\n",
       "          1.62881975e-01, -4.61204543e-02,  1.51989522e-01,\n",
       "          4.24299675e-02, -4.53271921e-01],\n",
       "        [-6.07474247e-01, -8.21480967e-02,  7.40422737e-02,\n",
       "         -5.54400215e-01, -1.24269829e-01, -6.21459487e-01,\n",
       "         -2.30067198e-01, -5.25257589e-01,  4.80937498e-01,\n",
       "         -7.82201655e-01,  1.75222148e-01,  4.31745134e-01,\n",
       "         -6.20398913e-01,  1.68954043e-01,  1.16268091e+00,\n",
       "         -3.23256042e-01, -3.23469413e-01, -1.78074638e-01,\n",
       "         -6.42979054e-01, -5.35934689e-01],\n",
       "        [-3.69233452e-01, -4.84198586e-01,  6.93474983e-02,\n",
       "         -6.22967740e-01, -5.77863840e-01, -4.64762476e-01,\n",
       "         -1.97888848e-01, -4.81277086e-01,  5.29892696e-01,\n",
       "         -6.57443604e-01,  1.40110252e-01,  3.02489596e-01,\n",
       "         -5.85213370e-01, -3.41538699e-01,  8.09915995e-01,\n",
       "         -1.19457795e-01, -8.51261376e-02, -3.60091708e-01,\n",
       "         -2.99017796e-01, -7.11147968e-01],\n",
       "        [-1.09565394e-01,  4.37911071e-02,  7.33270547e-02,\n",
       "         -3.44818610e-01,  7.08595120e-01, -4.30073622e-01,\n",
       "          1.00783526e-01, -3.77353726e-01,  3.31173669e-01,\n",
       "         -5.70689001e-02,  3.42760929e-01,  5.66088039e-01,\n",
       "         -3.42361579e-01,  9.16307517e-02,  6.92340012e-01,\n",
       "          1.46626528e-01, -3.52288148e-01, -3.03009694e-01,\n",
       "         -4.34144476e-01, -6.27010051e-01],\n",
       "        [-4.30453096e-01,  4.58780355e-02, -6.58515422e-02,\n",
       "         -5.06362677e-01, -8.10182354e-02, -2.72116625e-01,\n",
       "         -4.07333223e-01,  1.06078468e-01,  2.49824535e-01,\n",
       "          8.40199839e-02,  5.24392921e-01, -5.77899700e-02,\n",
       "         -4.85082080e-01, -3.55565676e-02,  2.60901594e-01,\n",
       "          2.52283089e-01,  1.36500599e-01,  1.72886791e-01,\n",
       "         -3.85889227e-01,  1.27841472e-01],\n",
       "        [-5.93454468e-02, -3.66837041e-01, -1.55132448e-01,\n",
       "         -3.58375872e-02, -6.20681997e-01, -3.60412942e-01,\n",
       "         -5.32975233e-02, -1.43681075e-01,  3.38791071e-01,\n",
       "         -5.57725963e-01,  3.77146429e-01,  6.27751782e-01,\n",
       "         -2.32727395e-01,  3.11821103e-01,  6.31285348e-01,\n",
       "         -3.06133138e-01, -2.76152268e-01,  5.29280347e-02,\n",
       "         -3.53822526e-01, -4.58019982e-01],\n",
       "        [-4.88384789e-01,  2.95105893e-02, -5.20602262e-02,\n",
       "         -1.87305372e-02, -2.16655088e-01, -8.74551822e-01,\n",
       "         -2.26567244e-01, -2.07924036e-01,  4.12696968e-01,\n",
       "         -1.00649968e-01,  1.30059347e-01,  2.71988334e-01,\n",
       "         -4.49993047e-01,  2.20061868e-01,  5.86075726e-01,\n",
       "         -1.15004895e-01, -7.60206761e-01,  1.83790329e-02,\n",
       "         -6.91311458e-01, -3.17034628e-01],\n",
       "        [-2.26011986e-01, -8.22180954e-02, -3.72757125e-01,\n",
       "          1.73153313e-01, -1.45164672e-02, -4.53520741e-01,\n",
       "         -3.05145291e-01, -2.02547150e-01, -4.99175035e-02,\n",
       "         -1.54737171e-01, -2.33926341e-01,  7.53345524e-01,\n",
       "         -2.22373152e-01,  9.45743155e-02, -6.88270073e-02,\n",
       "         -2.89939219e-02, -3.79741344e-01, -2.52409727e-01,\n",
       "         -4.10969873e-01, -1.27861190e-01],\n",
       "        [-1.46802704e-01, -2.76352817e-01,  3.06236341e-01,\n",
       "         -3.47610871e-01, -6.29841751e-01,  4.59555595e-01,\n",
       "         -6.63335789e-02, -5.52100143e-01,  1.38785225e-01,\n",
       "         -1.99609503e-01,  7.01587471e-01, -4.74079967e-01,\n",
       "         -3.86832088e-01,  1.64138774e-01,  4.11078895e-01,\n",
       "         -4.07790600e-02, -1.60915893e-01, -4.10224601e-01,\n",
       "         -1.07562773e-01,  1.47038761e-02]]),\n",
       " array([[ 0.29792802],\n",
       "        [ 0.41759903],\n",
       "        [-0.71344849],\n",
       "        [-1.51073569],\n",
       "        [ 2.3933528 ],\n",
       "        [-0.95414011],\n",
       "        [ 0.92964497],\n",
       "        [ 1.30466836],\n",
       "        [-0.92870428],\n",
       "        [ 1.00791141],\n",
       "        [-1.64939757],\n",
       "        [-1.56411542],\n",
       "        [-0.55864417],\n",
       "        [-1.43756883],\n",
       "        [-1.50719567],\n",
       "        [-0.10551555],\n",
       "        [ 1.30425806],\n",
       "        [-0.10174263],\n",
       "        [ 0.89543607],\n",
       "        [ 1.5637587 ]])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn = DNN(hidden_layer_sizes=(20,),\n",
    "          activation='relu',\n",
    "          solver='sgd',\n",
    "          learning_rate_init=0.5,  # 初始学习率\n",
    "          learning_rate='invscaling',  # 学习率的变化策略\n",
    "          power_t=0.1,  # 衰减指数\n",
    "          batch_size=200,\n",
    "          max_iter=3000,\n",
    "          random_state=420\n",
    "          ).fit(X_, y)\n",
    "\n",
    "# 查看最终生成的系数w\n",
    "dnn.coefs_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 怎么看w的结构？ \n",
    "type(dnn.coefs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 20)\n",
      "(20, 1)\n"
     ]
    }
   ],
   "source": [
    "for item in dnn.coefs_:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果有怎样的含义？  \n",
    "含有一层隐藏层的神经网络，会有两层连接：输入层-隐藏层，隐藏 层-输出层，输入层对隐藏层中有（输入层神经元个数*隐藏层神经元个数）个系数w，而隐 藏层到输出层有（隐藏层神经元个数 * 输出层神经元个数）个系数w。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41759641, -0.14841978, -0.42918494, -0.74355217,  0.38385418,\n",
       "       -0.7976191 , -0.15620847, -0.49008832,  0.43161849, -0.37004261,\n",
       "       -0.20199358,  0.22394727, -0.90181925, -0.45354304,  0.83416879,\n",
       "       -0.29374443, -0.18668718, -0.10676847, -0.06993405,  0.13247594])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.coefs_[0][0]  # 这就是输入层上的第一个神经元连接到隐藏层上的所有神经元的系数w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.41759641,  0.06855121, -0.16093251, -0.07628407,  0.36269543,\n",
       "        0.12797984,  0.05377088, -0.57817196, -0.09519285, -0.01303262,\n",
       "       -0.03753927,  0.03986439, -0.29988758, -0.28662712,  0.26311186,\n",
       "       -0.12470589, -0.13291044, -0.11835064, -0.1813472 ,  0.0866722 ,\n",
       "       -0.10184606, -0.34911867, -0.60747425, -0.36923345, -0.10956539,\n",
       "       -0.4304531 , -0.05934545, -0.48838479, -0.22601199, -0.1468027 ])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn.coefs_[0][:, 0] # 这就第一个隐藏层上的第一个神经元链接到输入层上的所有神经元的系数w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.01208511,  0.23006008, -0.28853019, -0.29669951,  0.3123024 ,\n",
       "        -0.37657032,  0.03147937,  0.53339565,  0.24325214,  0.02444767,\n",
       "        -0.25642082, -0.0451247 , -0.63745918,  0.10328563,  0.72275721,\n",
       "        -0.21191841,  0.17054416, -0.34092959,  0.36398215,  0.78700881]),\n",
       " array([-0.4722992])]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看最终生成的b以及b的结构 \n",
    "dnn.intercepts_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "for item in dnn.intercepts_:\n",
    "    print(item.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004384897719095809"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看现在的损失函数 \n",
    "dnn.loss_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "406px",
    "width": "222px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "409.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
